DATASET 1 — NYC TLC TAXI (Trips + Zones + Weather)
Complete Hands-On Task List (EDA + Preprocessing + Modeling)
________________________________________
1. Data Ingestion & Initial Inspection
•	Load Parquet taxi trip data ✅
•	Load taxi zone lookup CSV ✅
•	Load hourly weather CSV ✅
•	Inspect shapes (rows, columns) ✅
•	Inspect column names ✅
•	Inspect data types ✅
•	Inspect index meaning ✅
•	Parse pickup/dropoff timestamps ✅
•	Normalize timezones across datasets 
•	Check units and scales: ✅
    o	Distance (miles)✅
    o	Fare/amounts (USD)✅
    o	Time (local vs UTC)✅
•	Identify keys and identifiers ✅
•	Detect non-unique keys ✅
•	Determine granularity (trip-level events) ✅
•	Detect aggregation mismatches (trip vs hourly weather)
•	Verify schema expectations
•	Reconciliation rules when multiple records exist per key-period
________________________________________
2. Data Understanding & Semantic Validation
•	Validate column meanings (fare vs total_amount, distance semantics)
•	Validate domain rules:
    o	fare ≥ 0
    o	distance ≥ 0
    o	dropoff ≥ pickup
•	Classify columns (numeric / categorical / datetime / text)
•	Identify potential target variables:
    o	fare
    o	duration
    o	hourly demand
•	Identify potential leakage columns
•	Identify constant / near-constant columns
•	Text & ID hygiene:
    o	trim whitespace
    o	enforce casing
    o	validate ID formats
•	Canonicalize categorical values
________________________________________
3. Data Quality Checks
•	Missing value detection
•	Duplicate row detection
•	Duplicate trip detection (same key-time window)
•	Duplicate key detection
•	Invalid category detection (payment types, rate codes)
•	Out-of-range value detection
•	Impossible value detection
•	Cardinality inspection (zones, vendors)
•	Class imbalance detection
•	Referential integrity checks (zone IDs)
•	Granularity conflict checks
•	Temporal data integrity:
    o	clock skew detection
    o	event sequencing correctness
    o	latency distributions
    o	missing hours/days
•	Calendar anomaly detection:
    o	weekends
    o	holidays
    o	end-of-month effects
________________________________________
4. Combining Multiple Datasets (Data Integration)
Pre-Join Analysis
•	Identify join keys
•	Validate join key data types
•	Check key uniqueness
•	Analyze key overlap
•	Detect orphan keys
•	Assess many-to-many join risk
Row-wise Combinations
•	Vertical concatenation (if multiple months used)
•	Schema alignment before concat
•	Column reconciliation
•	Deduplication after concat
•	Temporal ordering
Column-wise Combinations
•	Index-based joins
•	Side-by-side concatenation
•	Handling partial overlaps
•	Column name conflict resolution
Relational Joins (Zones)
•	Inner join
•	Left join
•	Right join (diagnostic)
•	Outer join (diagnostic)
•	One-to-one validation
•	One-to-many validation
•	Join indicator analysis
•	Join validation rules
Time-Aware Joins (Weather)
•	Exact timestamp joins (failure case)
•	Nearest-key joins
•	Forward joins
•	Backward joins
•	Tolerance-based joins
•	As-of joins
•	Lag-aligned joins
•	Causality validation (no future weather)
Advanced Joins
•	Multi-key joins
•	Composite key joins
•	Conditional joins
•	Cross joins (diagnostic only)
Post-Join Validation
•	Row count reconciliation
•	Null inflation analysis
•	Duplicate creation detection
•	Key coverage analysis
•	Leakage detection
•	Drop helper columns
________________________________________
5. Target Variable Analysis
•	Define candidate targets (fare, duration, demand)
•	Target distribution analysis
•	Heavy-tail detection
•	Target outlier analysis
•	Target transformation
•	Temporal leakage checks
•	Target stability over time
•	Class imbalance strategies (if classification framing)
•	Label reliability checks (consistency over time)
________________________________________
6. Missing Data Analysis & Handling
•	Missingness pattern analysis
•	MCAR / MAR / MNAR hypothesis
•	Drop rows
•	Drop columns
•	Mean / median imputation
•	Group-wise imputation (zone/hour)
•	Forward/backward fill (weather)
•	Model-based imputation (optional)
•	Missing indicator creation
•	Distribution comparison pre/post imputation
________________________________________
7. Outlier Analysis & Treatment
•	IQR-based detection
•	Z-score detection
•	MAD detection
•	Contextual outlier analysis (time/zone-based)
•	Percentile capping
•	Winsorization
•	Clipping
•	Log / power transformation
•	Outlier isolation for analysis
________________________________________
8. Statistical Exploration (Core EDA)
Univariate
•	Mean, median, mode
•	Variance, standard deviation
•	Skewness, kurtosis
•	Value counts
•	Distribution shape analysis
•	Empirical quantiles
•	Tail heaviness
•	Zero-inflation checks
Bivariate / Multivariate
•	Correlation (Pearson, Spearman)
•	Covariance analysis
•	Cross-tabulation
•	Group-by aggregation
•	Conditional statistics
•	Target–feature relationships
•	Non-linear association measures
•	Simpson’s paradox checks
•	Collinearity diagnostics (VIF)
•	Partial correlations
•	Clustering tendency checks
•	Manifold structure diagnostics (UMAP/t-SNE, diagnostic)
Hypothesis Testing (EDA-level)
•	Parametric vs non-parametric tests
•	Multiple testing correction
•	Power analysis (sanity check)
________________________________________
9. Visualization-Based Exploration
•	Histograms
•	Box plots
•	KDE plots
•	Scatter plots
•	Pair plots
•	Heatmaps
•	Line plots
•	Time series plots
•	Category frequency plots
•	Faceted plots (zone, weekday, hour)
________________________________________
10. Data Transformation
•	Unit conversion
•	Log / power transforms
•	Box-Cox / Yeo-Johnson
•	Standardization
•	Normalization
•	Robust scaling
•	Binning / discretization
•	Rank transformation
•	Rolling / exponential smoothing
•	Learned transformations (quantile)
•	Track invertibility of transforms
________________________________________
11. Feature Engineering
•	Mathematical features
•	Ratio and difference features
•	Interaction features
•	Aggregation features
•	Rolling window features (leak-safe)
•	Lag features
•	Cumulative features
•	Datetime decomposition
•	Holiday/event features
•	Seasonality & trend decomposition (STL)
•	Demand recency/frequency features
•	Weather interaction features
•	Sessionization concepts (hourly buckets)
________________________________________
12. Encoding Categorical Variables
•	Rare category grouping
•	Label encoding
•	One-hot encoding
•	Ordinal encoding
•	Frequency encoding
•	Target encoding (leak-safe)
•	Hash encoding (diagnostic)
•	High-cardinality safeguards
________________________________________
13. Feature Selection & Dimensionality Reduction
•	Variance thresholding
•	Correlation-based pruning
•	Univariate statistical tests
•	Mutual information analysis
•	Model-based importance
•	Recursive feature elimination
•	PCA / SVD
•	Stability checks across time splits
•	Redundancy pruning via clustering
________________________________________
14. Data Consistency & Validation
•	Schema validation
•	Type coercion
•	Range validation
•	Constraint enforcement
•	Business rule validation
•	Cross-field consistency checks
•	Temporal ordering validation
________________________________________
15. Dataset Splitting & Final Preparation
•	Random split (diagnostic)
•	Time-based split (primary)
•	Group-based split (zone/vendor)
•	Time-aware cross-validation
•	Leakage prevention checks
•	Pipeline freezing
________________________________________
16. Modeling & Evaluation (Within Current Scope)
•	Naive baseline (mean / last-hour)
•	Simple linear / tree baseline
•	Metric selection aligned to target
•	Residual analysis
•	Error distribution analysis
•	Slice metrics (zone, time, weather)
•	Sensitivity to outliers
•	Model sanity checks

